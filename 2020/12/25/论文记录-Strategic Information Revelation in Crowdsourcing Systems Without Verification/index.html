<!DOCTYPE html>


<html lang="zh-CN">

<head>
  <link rel="stylesheet" type="text/css" href="/css/matery.css">
  <meta charset="utf-8" />
    
  <meta name="description" content="无验证的众包系统中的策略性信息披露" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    论文记录-Strategic Information Revelation in Crowdsourcing Systems Without Verification |  左边
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">
  
<link rel="stylesheet" href="/css/custom.css">

  
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
  
  

  

</head>

</html>

<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-论文记录-Strategic Information Revelation in Crowdsourcing Systems Without Verification"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  论文记录-Strategic Information Revelation in Crowdsourcing Systems Without Verification
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/12/25/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95-Strategic%20Information%20Revelation%20in%20Crowdsourcing%20Systems%20Without%20Verification/" class="article-date">
  <time datetime="2020-12-25T01:38:43.000Z" itemprop="datePublished">2020-12-25</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">3.9k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">15 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Strategic-Information-Revelation-in-Crowdsourcing-Systems-Without-Verification"><a href="#Strategic-Information-Revelation-in-Crowdsourcing-Systems-Without-Verification" class="headerlink" title="Strategic Information Revelation in Crowdsourcing Systems Without Verification"></a>Strategic Information Revelation in Crowdsourcing Systems Without Verification</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ol>
<li>本文研究：无需验证解决方案、激励员工提供高质量解决方案的众包平台</li>
<li>本文假设：信息不对称、平台具有信息优势——平台知道有关workers解决方案的平均准确性的更多信息，可以向workers策略性披露信息。根据平台公开的信息，workers判断自己认真完成任务后所获得的奖励。</li>
<li>workers类型：<ol>
<li>naive workers：完全信任平台公开的信息</li>
<li>strategic workers：基于平台公开信息更新自己的先验信念</li>
</ol>
</li>
<li>本文发现：<ol>
<li>对于naive workers：始终宣布高平均精度</li>
<li>对于strategic workers：有动机宣布低于实际值的平均精度</li>
<li>平台的回报可能减少高精度workers </li>
</ol>
</li>
</ol>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ol>
<li>互联网的发展使得多种在线任务的众包具有可行性。</li>
<li>高质量的众包任务解决方案需要worker付出足够的努力，因此平台需要提供激励；而平台无法获取真实结果验证解决方案时，设计激励方案会很难，进而引出IEWV问题。</li>
<li>IEWV(Information elicitation without verification)：未验证的信息挖掘，大多数研究对称信息场景；而实际上，平台往往有更多信息。</li>
<li>本文采用多数投票方案：如果一个worker与其他workers的大多数解决方案相匹配，他将获得一个一致性奖励。</li>
<li>本文假设平台有一个额外决策：信息披露。该场景中，workers由高精度和低精度的混合构成，平台知道每种类型的数量，而workers不知道。</li>
<li>本文研究：<ol>
<li>平台是否有披露信息的动机</li>
<li>平台是否操纵被披露的信息</li>
<li>平台的最优信息披露策略——&gt;平台如何利用信息不对称</li>
</ol>
</li>
<li>平台与workers之间的交互（三阶段）：<ol>
<li>平台决定信息披露策略</li>
<li>平台决定一致性奖励</li>
<li>workers决定是否努力完成任务以及是否如实报告解决方案</li>
<li>上述三阶段结束后，平台收集workers上报的解决方案并根据三阶段来决定一致性奖励</li>
</ol>
</li>
<li>本文考虑两种类型的workers：<ol>
<li>naive workers：完全相信平台、workers推理平台公开信息是否可靠的能力有限，可以作为基准</li>
<li>strategic workers：不相信平台，有很高推理能力</li>
</ol>
</li>
</ol>
<h3 id="Key-Contributions"><a href="#Key-Contributions" class="headerlink" title="Key Contributions"></a>Key Contributions</h3><ol>
<li>研究IEWV问题的策略性信息披露：非凸问题，但是可以利用特殊结构求最优解</li>
<li>workers的均衡策略：证明workers之间存在多重均衡，在适当的信息披露和报酬设计下，所有workers努力工作并如实报告自己解决方案是其帕累托最优</li>
<li>平台信息披露策略：<ol>
<li>naive workers：始终公布一个与实际值无关的较高的平均准确率</li>
<li>strategic workers：有动机公布一个低于实际值的平均准确率</li>
</ol>
</li>
<li>性能评估：数值实验<ol>
<li>平台报酬增加了workers对高准确率workers数量的先验信念</li>
<li>平台报酬可能会减小高准确率workers的数量</li>
</ol>
</li>
</ol>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Information-Elicitation-Without-Verification-IEWV"><a href="#Information-Elicitation-Without-Verification-IEWV" class="headerlink" title="Information Elicitation Without Verification(IEWV)"></a>Information Elicitation Without Verification(IEWV)</h3><ol>
<li>设计适当的激励</li>
<li>同伴预测</li>
<li>大都假设信息对称</li>
</ol>
<h3 id="Strategic-Information-Revelation"><a href="#Strategic-Information-Revelation" class="headerlink" title="Strategic Information Revelation"></a>Strategic Information Revelation</h3><ol>
<li>不完全信息中的cheap talk问题——假设平台不会说谎</li>
<li>考虑信息获取和揭示代价的劝说博弈——认为信息披露是唯一的决策</li>
</ol>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h3 id="Workers’-Decisions-and-Payoffs"><a href="#Workers’-Decisions-and-Payoffs" class="headerlink" title="Workers’ Decisions and Payoffs"></a>Workers’ Decisions and Payoffs</h3><ol>
<li>任务和workers：<ol>
<li>任务：二值问题，例如判断数学问题求解方案是否正确，解空间<code>{1， -1}</code>，分别表示正确和错误。</li>
<li>workers：$N$个，$x_i^{estimate}$表示第$i$个worker对该任务解的估计值，$x_i^{report}$表示第$i$个worker对该任务解的上报值，这二者可能一样也可能不同。</li>
</ol>
</li>
<li>workers的努力策略：<ol>
<li>worker可以决定是否努力工作，求解准确性和他选择的努力程度有关，努力程度为<code>{0,1}</code>两种。<ol>
<li>努力程度为0时，worker求解准确率为0.5，代价为0，且无法获取关于任务解方案的任何信息（即其估计值为真或假的概率相等）</li>
<li>努力程度为1时，其求解准确率会提高为$p_i$，代价为$c$。</li>
</ol>
</li>
<li>workers的异构：$N$个workers中有$k$个高准确率的worker（准确率为$p_h$）使用集合$N_h$表示；$N-k$个低准确率的worker（准确率为$p_l$），使用集合$N_l$表示。两个准确率值均大于0.5小于1。</li>
</ol>
</li>
<li>worker的上报策略：<ol>
<li>对于不努力的worker：策略唯一，随机上报，用<code>rd</code>表示</li>
<li>对于努力的worker：策略空间<code>{1,-1}</code>，分别表示如实报告和谎报</li>
<li>workers可以共谋，大家都报告1或者-1，但对于在线众包系统，这样的共谋并不现实；平台检测到共谋则会删除该worker，因此认为workers的报告策略是独立的，且只有<code>{rd,1,-1}</code>这三个选项。</li>
<li>$s_i=(e_i,r_i)$表示第$i$个worker的努力策略和报告策略，具体来说$s_i\in S_i=\{(0,rd),(1,1),(1,-1)\}$</li>
</ol>
</li>
<li>一致性奖励：<ol>
<li>报告值和大多数人一样的worker可以得到奖励$R$。</li>
<li>$G_i(s;\epsilon)$表示第$i$个worker收到$R$的概率，其中，$s=(e_i,r_i)$，$\epsilon$是平台策略，在后面进行分析。</li>
</ol>
</li>
<li>worker的收益：$u_i(s;\epsilon,R)=G_i(s;\epsilon)\cdot R-e_i\cdot c$</li>
</ol>
<h3 id="Platform’s-Decisions-and-Payoff"><a href="#Platform’s-Decisions-and-Payoff" class="headerlink" title="Platform’s Decisions and Payoff"></a>Platform’s Decisions and Payoff</h3><ol>
<li><p>平台的信息披露策略：</p>
<ol>
<li><p>平台拥有的信息优势：workers求解准确率的分布，也就是高准确率workers的数量$k$</p>
</li>
<li><p>平台和workers之间非对称信息披露的贝叶斯说服框架：</p>
<ol>
<li><p>平台和workers都不知道$k$，平台需要进行长期信息披露策略：</p>
<ol>
<li><p>平台虽然不知道$k$，但是知道$k$的分布，从而得到先验信念$\mu^{prior}=(\mu_{high}^{prior},\mu_{low}^{prior})$，其中$\mu_{high}^{prior}=Pr(k=k^{high})$，$\mu_{low}^{prior}=Pr(k=k^{low})$。$\mu_{high}^{prior}+\mu_{low}^{prior}=1$，且$k^{high}$和$k^{low}$是$k$的两个可能取值。</p>
</li>
<li><p>这个先验同时也是workers的，大家都一样。</p>
</li>
<li><p>注意，出于简化，上述公式中$k$的分布是两点分布，本方法同样适用于其他分布的情况。</p>
</li>
<li><p>在$k$被发现之前，平台会预定一个信息披露策略（？是否公开——从后文看是公开的，或者说是workers能发现其规律）。</p>
</li>
<li><p>平台可以有多个任务，每个任务有各自对应的$k$，在workers到来之前（也即是在$k$被发现之前），平台会先决定信息披露策略，并承诺会按这个策略执行，从而建立良好信誉。</p>
</li>
<li><p>$\epsilon = (\epsilon^h, \epsilon^l)\in [0,1]^2$：平台的信息披露策略。假设当$k=k^{low}$时，平台宣称$k_p^{anu}=k^{high}$的概率是$\epsilon^h$，而反之，当$k=k^{high}$时，平台宣称$k_p^{anu}=k^{low}$的概率是$\epsilon^l$。</p>
</li>
<li><p>总结一下就是平台会按下列概率决策：</p>
<p>$Pr(k_p^{anu}=k^{high}|k=k^{low})=\epsilon^h$</p>
<p>$Pr(k_p^{anu}=k^{low}|k=k^{low})=1-\epsilon^h$</p>
<p>$Pr(k_p^{anu}=k^{high}|k=k^{high})=1-\epsilon^l$</p>
<p>$Pr(k_p^{anu}=k^{low}|k=k^{high})=\epsilon^l$</p>
<p>即：k有两个取值，一个high，一个low，当真实的k是high时，平台说谎的概率是$\epsilon^l$；当真实的k是low时，平台说谎的概率是$\epsilon^h$。</p>
</li>
</ol>
</li>
<li><p>workers执行任务，平台观察到$k$，workers尚且不知道；</p>
</li>
<li><p>平台依据之前决定的策略公开$k_p^{anu}$，可能和真实$k$不同，平台决定的$\epsilon$会影响workers对$k$的后验信念，从而影响平台的信誉和收益。</p>
</li>
<li><p>workers可以通过重复与平台交互从而了解平台的信息披露策略，也可以通过平台反馈以及信誉系统来了解信息披露策略。</p>
</li>
</ol>
</li>
</ol>
</li>
<li><p>平台的奖励设计策略：$R$，决定worker均衡收益</p>
</li>
<li><p>平台的收益：准确率和代价之间的均衡</p>
<p>$U_p(\epsilon,R,k;s)=\beta P_a(\epsilon,R,k;s)-E\{R^{tot}(\epsilon,R,k;s)\}$</p>
<ol>
<li>$P_a(\epsilon,R,k;s)$表示workers的任务聚合准确率，使用少数服从多数的规则来计算该概率。</li>
<li>$\beta$表示平台对聚合准确率的估值（从公式上理解感觉更像是说当聚合结果是正确的时候所得到的收益）</li>
<li>$E\{R^{tot}(\epsilon,R,k;s)\}$表示对总的一致性奖励的预期支出（这里的$R^{tot}$是指什么？）</li>
</ol>
</li>
</ol>
<h2 id="SOLVING-THREE-STAGE-MODEL"><a href="#SOLVING-THREE-STAGE-MODEL" class="headerlink" title="SOLVING THREE-STAGE MODEL"></a>SOLVING THREE-STAGE MODEL</h2><p>本章节使用逆向归纳法，仅分析strategic worker。</p>
<h3 id="Worker-Equilibrium-Behaviors-in-Stage-III"><a href="#Worker-Equilibrium-Behaviors-in-Stage-III" class="headerlink" title="Worker Equilibrium Behaviors in Stage III"></a>Worker Equilibrium Behaviors in Stage III</h3><ol>
<li><p>前提：给定平台策略$\epsilon$和$R$，每个worker选择自己的努力程度和报告策略$s_i$来最大化自身收益</p>
</li>
<li><p>worker的信念更新：平台公布$k_p^{anu}$之前，workers有对$k$的先验信念$\mu^{prior}$（是每人一个还是所有worker共用？）</p>
<ol>
<li><p>平台公布$k_p^{anu}$后，workers基于先验信念和平台公布值更新后验信念$\mu_w^{post,str}|k_p^{anu}$，其中$w\in \{high,low\}$。计算如下：</p>
<script type="math/tex; mode=display">
\mu_{high}^{post,str}|k^{high}(\epsilon)=\frac{(1-\epsilon^l)\mu_{high}^{prior}}{(1-\epsilon^l)\mu_{high}^{prior}+\epsilon^h\mu_{low}^{prior}}</script><script type="math/tex; mode=display">
\mu_{low}^{post,str}|k^{high}(\epsilon)=\frac{\epsilon^h\mu_{low}^{prior}}{(1-\epsilon^l)\mu_{high}^{prior}+\epsilon^h\mu_{low}^{prior}}</script><script type="math/tex; mode=display">
\mu_{high}^{post,str}|k^{low}(\epsilon)=\frac{\epsilon^l\mu_{low}^{prior}}{\epsilon^l\mu_{high}^{prior}+(1-\epsilon^h)\mu_{low}^{prior}}</script><script type="math/tex; mode=display">
\mu_{low}^{post,str}|k^{low}(\epsilon)=\frac{(1-\epsilon^h)\mu_{low}^{prior}}{\epsilon^l\mu_{high}^{prior}+(1-\epsilon^h)\mu_{low}^{prior}}</script><p>推导过程用到了<a href="https://zhuanlan.zhihu.com/p/134036707" target="_blank" rel="noopener">贝叶斯公式</a>。</p>
<p>前两行表示平台宣布$k=k^{high}$时，worker对$k$实际值的后验信念；后两行表示平台宣布$k=k^{low}$时，worker对$k$实际值的后验信念。</p>
</li>
<li><p>显然，第一个公式里，随着$\epsilon^h$的增加，workers对k为high的后验信念逐渐减小，也就是说，如果平台在k实际为low时说谎的概率增加，则workers在听到平台说k为high时，会怀疑平台说谎；类似地，在第四个公式中，随着$\epsilon^l$的增加，workers对k为low的后验信念逐渐减小，也就是说，如果平台在k实际为high时说谎的概率增加，则workers在听到平台说k为low时，会怀疑平台，进而减小后验信念。</p>
</li>
</ol>
</li>
<li><p>worker的均衡策略：worker根据后验信念做出是否努力以及是否如实汇报的决策，本文关注对称纳什均衡——相同类型（任务求解准确率）的worker会有相同的决策。</p>
<ol>
<li><p>定义1：</p>
<ol>
<li>$n-SNE$：$(s_i^*=(0,rd), \forall i\in N)$，没有worker会努力和如实报告</li>
<li>$f-SNE$：$(s_i^*=(1,1), \forall i\in N)$， 所有worker都努力和如实报告</li>
<li>$p-SNE$：$(s_i^<em>=(1,1), \forall i\in N_h, s_j^</em>=(0,rd), \forall j\in N_l)$，高准确率的worker会努力和如实报告，低准确率的worker会不努力和随机报告</li>
</ol>
</li>
<li><p>定理1：</p>
<ol>
<li>给定任意$\epsilon\in [0,1]^2$，$R\geq 0$时一定存在一个$n-SNE$.</li>
<li>给定任意$\epsilon\in [0,1]^2$，始终存在阈值$R_f^{str}(\epsilon, k_p^{anu})&gt; 0$，使得当且仅当$R&gt;R_f^{str}(\epsilon,k_p^{anu})$时存在$f-SNE$.</li>
<li>当$\epsilon\in \Phi=\{\epsilon\in [0,1]^2|condition (11) \}$成立时，存在两个阈值$0&lt;R_{pl}^{str}(\epsilon,k_p^{anu})\leq R_{ph}^{str}(\epsilon, k_p^{anu})$，使得当且仅当$R_{pl}^{str}(\epsilon,k_p^{anu})\leq R \leq R_{ph}^{str}(\epsilon, k_p^{anu})$时，存在$p-SNE$. $condition (11)$如下：</li>
</ol>
<script type="math/tex; mode=display">
\frac{2p_h-1}{2p_l-1}(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}-1}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}-1}^{majority})\geq \mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}}^{majority} \tag{11}</script><p>​        在该公式中，$P_{k^{high}-1}^{majority}$是指：当$k^{high}-1$个高准确率workers决定采取策略$(1,1)$且剩下的其他workers都决定采取策略$(0,rd)$时，$N-1$个workers的解决方案中的大多数是正确的概率（也就是多数一致方案是正确的概率）</p>
<p>​        $P_{k^{low}-1}^{majority}$是指：当$k^{low}-1$个高准确率workers决定采取策略$(1,1)$且剩下的其他workers决定采取策略$(0,rd)$时，$N-1$个workers的解决方案中的大多数是正确的概率（也就是多数一致方案是正确的概率）</p>
<p>​        $P_{k^{high}}^{majority}$是指：$k^{high}$个高准确率worker决定采取策略$(1,1)$，剩下的其他workers决定采取策略$(0,rd)$时，$N-1$个workers的解决方案中的大多数是正确的概率（也就是多数一致方案是正确的概率）</p>
<p>​        $P_{k^{low}}^{majority}$是指：$k^{low}$个高准确率worker决定采取策略$(1,1)$，剩下的其他workers决定采取策略$(0,rd)$时，$N-1$个workers的解决方案中的大多数是正确的概率（也就是多数一致方案是正确的概率）</p>
<p>​        这个公式算起来很复杂，它表达的场景是：当选择努力时，高准确率worker相信他们更有可能拿到奖励（而不是低准确率worker），也就是说高准确率worker认为自己是大多数的那部分。反之，当这个公式不满足时，高准确率worker会觉得自己拿到奖励的概率很低，从而使得高准确率worker的期望收益很低。此时，高准确率worker不会努力，而是选择降低成本，进而不存在$p-SNE$。</p>
</li>
</ol>
</li>
<li><p>推论1：</p>
<ol>
<li><p>对于一个固定的$\epsilon^l$，如果$k_p^{anu}=k^{high}$，则定理1中的$R_f^{str}(\epsilon,k_p^{anu})$和$R_{pl}^{str}(\epsilon,k_p^{anu})$随$\epsilon^h$增加而增加；反之，如果$k_p^{anu}=k^{low}$，则这两个都随$\epsilon^h$增加而减小。</p>
<p>说明：如果平台更喜欢把$k_p^{anu}$谎报成$k^{high}$（也就是说在$k^{low}$时说谎），那么为了达成$f-SNE$和$p-SNE$，平台需要提供更高报酬（也就是更大的$R$）。分析原因：这种情况会让workers觉得实际的$k$并不是$k^{high}$而是$k^{low}$，也就是说$\mu_{high}^{post,str}|k^{high}(\epsilon)$会减小，因此通过多数一致获得的奖励会减少，而为了激励workers，平台就需要提高奖励，从而提高workers的期望收益。</p>
</li>
<li><p>对于一个固定的$\epsilon^h$，如果$k_p^{anu}=k^{high}$，则定理1中的$R_f^{str}(\epsilon,k_p^{anu})$和$R_{pl}^{str}(\epsilon,k_p^{anu})$随$\epsilon^l$增加而增加；反之，如果$k_p^{anu}=k^{low}$，则这两个都随$\epsilon^l$增加而减小。</p>
<p>说明：如果平台更喜欢把$k_p^{anu}$谎报成$k^{low}$（也就是说在$k^{high}$时说谎），那么为了达成$f-SNE$和$p-SNE$，平台也一样需要提高报酬来激励。这里的推导可以看前面workers更新后验信念那里的公式来理解。</p>
</li>
<li><p>对于适当的$\epsilon$和$R$，定理1中的几个不同的$SNE$可以共存。</p>
</li>
</ol>
</li>
<li><p>定理2：帕累托最优：对于任意给定$\epsilon$和$R$，workers之间存在一个帕累托最优均衡解。</p>
<p>本文假设当多个均衡解共存时，workers会选择帕累托最优。</p>
</li>
</ol>
<h3 id="Platform-Reward-Design-in-Stage-II"><a href="#Platform-Reward-Design-in-Stage-II" class="headerlink" title="Platform Reward Design in Stage II"></a>Platform Reward Design in Stage II</h3><p>这一部分分析对于给定的$\epsilon$，平台观察$k$并决定$R$，从而在第三阶段达到帕累托最优。</p>
<ol>
<li><p>定义2：$z\in \{n,f,p\}$表示均衡解索引</p>
<ol>
<li><p>$P_z(k)$：均衡$z-SNE$的任务聚合准确率</p>
</li>
<li><p>$E\{R_z^{tot}(\epsilon,k,k_p^{anu})\}$：均衡$z-SNE$的总期望一致性奖励</p>
</li>
<li><p>$B_z(\epsilon,k,k_p^{anu})$：对于每单位$R$，均衡解从$n-SNE$提升到$z-SNE$所带来的平均准确率的提升，计算方式如下：</p>
<script type="math/tex; mode=display">
B_z(\epsilon,k,k_p^{anu})=\frac{P_z(k)-P_n(k)}{E\{R_z^{tot}(\epsilon,k,k_p^{anu})\}}</script></li>
</ol>
</li>
<li><p>定理3：</p>
<ol>
<li><p>如果$(11)$成立且$B_p(\epsilon,k,k_p^{anu})&gt;B_f(\epsilon,k,k_p^{anu})$，则平台的最优奖励为：</p>
<script type="math/tex; mode=display">
R^*=\left\{
\begin{aligned}
&0, &if \ \ \beta<\frac{1}{B_p(\epsilon,k,k_p^{anu})}\\
&R_{pl}^{str}(\epsilon,k_p^{anu}), &if\ \ \frac{1}{B_p(\epsilon,k,k_p^{anu})} \leq \beta<\widetilde\beta(\epsilon,k,k_p^{anu}) \\
&R_{f}^{str}(\epsilon,k_p^{anu}), &if\ \ \beta\geq \widetilde\beta(\epsilon,k,k_p^{anu})
\end{aligned}
\right.</script><p>其中，$\widetilde\beta(\epsilon,k,k_p^{anu})=\frac{E\{R_f^{tot}(\epsilon,k,k_p^{anu})-E\{R_p^{tot}(\epsilon,k,k_p^{anu})}{P_f(k)-P_p(k)}$</p>
</li>
<li><p>如果$(11)$不成立或者$B_p(\epsilon,k,k_p^{anu})&lt;B_f(\epsilon,k,k_p^{anu})$，则平台的最优奖励为：</p>
<script type="math/tex; mode=display">
R^*=\left\{
\begin{aligned}
&0, &if \ \ \beta<\frac{1}{B_f(\epsilon,k,k_p^{anu})}\\
&R_{f}^{str}(\epsilon,k_p^{anu}), &if\ \ \beta\geq \frac{1}{B_f(\epsilon,k,k_p^{anu})}
\end{aligned}
\right.</script><p>注意，$(11)$是达到$p-SNE$所必须的条件。</p>
</li>
</ol>
</li>
<li><p>定理3说明了：</p>
<ol>
<li>如果$p-SNE$存在，且它比$f-SNE$的单位收益准确率提升更高，且平台的估值$\beta$是温和的，平台会通过选择$R^*=R_{pl}^{str}(\epsilon,k_p^{anu})$引出$p-SNE$作为第三阶段的帕累托均衡来最大化自己的收益。</li>
<li>如果$p-SNE$不存在，或者它比$f-SNE$的单位收益准确率提升低，那么$p-SNE$对平台而言就不是最好的均衡解。当$\beta$很大时，平台会通过选择$R^*=R_f^{str}(\epsilon,k_p^{anu})$引出$f-SNE$作为第三阶段的帕累托最优。</li>
</ol>
</li>
</ol>
<h3 id="Platform-Information-Revelation-in-Stage-I"><a href="#Platform-Information-Revelation-in-Stage-I" class="headerlink" title="Platform Information Revelation in Stage I"></a>Platform Information Revelation in Stage I</h3><p>这一部分讨论平台的信息披露策略。在该阶段中，平台决定自己的信息披露策略$\epsilon = (\epsilon^h,\epsilon^l)\in[0,1]^2$，并预测自己在第二阶段中的$R$和workers在第三阶段中的帕累托均衡。</p>
<p>重复一下前文的符号表示：</p>
<blockquote>
<p>$\epsilon = (\epsilon^h, \epsilon^l)\in [0,1]^2$：平台的信息披露策略。假设当$k=k^{low}$时，平台宣称$k_p^{anu}=k^{high}$的概率是$\epsilon^h$，而反之，当$k=k^{high}$时，平台宣称$k_p^{anu}=k^{low}$的概率是$\epsilon^l$。</p>
<p>总结一下就是平台会按下列概率决策：</p>
<p>$Pr(k_p^{anu}=k^{high}|k=k^{low})=\epsilon^h$</p>
<p>$Pr(k_p^{anu}=k^{low}|k=k^{low})=1-\epsilon^h$</p>
<p>$Pr(k_p^{anu}=k^{high}|k=k^{high})=1-\epsilon^l$</p>
<p>$Pr(k_p^{anu}=k^{low}|k=k^{high})=\epsilon^l$</p>
<p>即：k有两个取值，一个high，一个low，当真实的k是high时，平台说谎的概率是$\epsilon^l$；当真实的k是low时，平台说谎的概率是$\epsilon^h$。</p>
</blockquote>
<ol>
<li><p>定理4：对平台而言，设置为$\epsilon^h=1,\epsilon^l=0$并不总是最优解。</p>
<p>换言之，宣称$k_p^{anu}=k^{high}$并不总是最好的，具体分析如下：</p>
<p>首先，复习内容：$k$的真实值影响第2阶段中的奖励设计，而平台对$k$的宣称值$k_p^{anu}$影响第3阶段中workers的行为。考虑一下4种情况：</p>
<ol>
<li>Case $(h,h)$: $k=k^{high}$ 且 $k_p^{anu}=k^{high}$，出现概率$Q_{h,h}(\epsilon)=\mu_{high}^{prior}(1-\epsilon^l)$</li>
<li>Case $(h,l)$: $k=k^{high}$ 且 $k_p^{anu}=k^{low}$，出现概率$Q_{h,l}(\epsilon)=\mu_{high}^{prior}\epsilon^l$</li>
<li>Case $(l,h)$: $k=k^{low}$ 且 $k_p^{anu}=k^{high}$，出现概率$Q_{l,h}(\epsilon)=\mu_{low}^{prior}\epsilon^h$</li>
<li>Case $(l,l)$: $k=k^{low}$ 且 $k_p^{anu}=k^{low}$，出现概率$Q_{l,l}(\epsilon)=\mu_{low}^{prior}(1-\epsilon^h)$</li>
</ol>
<p>固定$\epsilon^l$，平台的期望收益为：</p>
<script type="math/tex; mode=display">
E\{U_p(\epsilon^h)\}=Q_{h,h}(\epsilon^h)U_{h,h}(\epsilon^h)+Q_{h,l}(\epsilon^h)U_{h,l}(\epsilon^h)+Q_{l,h}(\epsilon^h)U_{l,h}(\epsilon^h)+Q_{l,l}(\epsilon^h)U_{l,l}(\epsilon^h)</script><p>$U_{h,h}$表示在Case $(h,h)$的情况下，平台在第2阶段最优化奖励值后的最大收益。其他几个U也是类似的含义。</p>
<p>接下来分析期望收益随披露策略的变化趋势。</p>
</li>
<li><p>引理1：</p>
<ol>
<li>$U_{h,h}(\epsilon^h),U_{l,h}(\epsilon^h),Q_{l,l}(\epsilon^h)$随$\epsilon^h$增加而减小。</li>
<li>$U_{h,l}(\epsilon^h),U_{l,l}(\epsilon^h),Q_{l,h}(\epsilon^h)$随$\epsilon^h$增加而增加。</li>
</ol>
<p>分析：$Q_{l,l}(\epsilon^h)$和$Q_{l,h}(\epsilon^h)$随$\epsilon^h$的变化从定义即可看出。接下来用Case $(h,h)$ 中的 $U_{h,h}(\epsilon^h)$作为例子来分析。在推论1中可知，随$\epsilon^h$增加，平台需要支付更大的奖励$R$来激励workers，而这会减小平台的收益。其他几个U也是类似的分析思路。</p>
<p>而由于$E\{U_p(\epsilon^h)\}$的几部分单调性不同，因此无法直接分析出平台收益随$\epsilon^h$的变化趋势。同样的，$E\{U_p(\epsilon^l)\}$也无法分析变化趋势。从而得出定理4的结论。</p>
</li>
</ol>
<p>具体的平台披露策略因为太复杂了，所以没法分析，在实验部分进行了数值实验。</p>
<h2 id="NUMERICAL-RESULTS"><a href="#NUMERICAL-RESULTS" class="headerlink" title="NUMERICAL RESULTS"></a>NUMERICAL RESULTS</h2><p>这一部分进行数值实验，研究两类workers：策略型和天真型，天真型的符号表达沿用前文中策略型的，只是把str改成了nai，具体如下：</p>
<script type="math/tex; mode=display">
\left\{
\begin{aligned}
\mu_{high}^{post,nai}|k^{high}=\mu_{low}^{post,nai}|k^{low}=1\\
\mu_{high}^{post,nai}|k^{low}=\mu_{low}^{post,nai}|k^{high}=0\\
\end{aligned}
\right.</script><p>接下来的实验结果说明：平台始终向天真的工人宣布高平均工人准确率是最佳的（也就是$k=k^{high}$），但对策略型工人来说并非如此。我们还显示了一个反直觉的结果，表明平台的收益随高准确率workers的准确率提高而提高，随高准确率workers的数量提高而减小。</p>
<h3 id="Impact-of-Worker-Characteristics"><a href="#Impact-of-Worker-Characteristics" class="headerlink" title="Impact of Worker Characteristics"></a>Impact of Worker Characteristics</h3><p>这一部分研究高准确率workers的准确率$p_h$对平台最优收益、workers总收益（所有workers的收益和）和社会福利（平台收益+workers收益）的影响。</p>
<p>参数：workers数量$N=100$，高准确率workers的准确率$p_h\in(0.7,0.8),step=0.02$，低准确率workers的准确率$p_l=0.6$，对$k$的先验信念$\mu_{high}^{prior}=0.7,\mu_{low}^{prior}=0.3$，$k$的取值$k^{low}=20,k^{high}\in\{50,70\}$，workers努力的成本$c=1$，平台对聚合准确的估值$\beta=1000$。</p>
<p>分析图像：</p>
<ol>
<li>平台收益随$p_h$增加而增加，对于某些$p_h$随$k^{high}$增加（指从50变成70）而减小。</li>
<li>天真的workers给平台带来的收益更高。</li>
<li>workers收益可能随$p_h$增加而减小。</li>
<li>社会财富随$p_h$增加而增加。</li>
</ol>
<h3 id="Impact-of-Worker-Prior-Belief"><a href="#Impact-of-Worker-Prior-Belief" class="headerlink" title="Impact of Worker Prior Belief"></a>Impact of Worker Prior Belief</h3><p>这一部分研究先验信念对平台最优收益、workers总收益和平台披露策略的影响。</p>
<p>参数：workers数量$N=100$，高准确率workers的准确率$p_h=0.75$，低准确率workers的准确率$p_l=0.6$，对$k$的先验信念$\mu_{high}^{prior}\in\{0.01,0.2,0.4,0.6,0.8,0.99\}$，$k$的取值$k^{low}=20,k^{high}\in\{50,70\}$，workers努力的成本$c=1$，平台对聚合准确的估值$\beta=1000$。</p>
<p>分析图像：</p>
<ol>
<li>平台收益随先验$\mu_{high}^{prior}$增加而增加。</li>
<li>策略型workers的聚合收益随先验$\mu_{high}^{prior}$增加而减小，天真型workers的聚合收益与先验$\mu_{high}^{prior}$无关。</li>
<li>面对天真型workers，平台始终宣称$k=k^{high}$是最优的；面对策略型workers则不是这样。</li>
<li>面对策略型workers时，平台的最优$\epsilon^{h}$随先验$\mu_{high}^{prior}$增加而减小，最优$\epsilon^{l}$随先验$\mu_{high}^{prior}$增加而增加。</li>
</ol>
<h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2><ol>
<li>策略性信息披露问题——非凸规划</li>
<li>naive workers：总是公开一个较高的平均准确率</li>
<li>strategic workers：收益和平台信用的平衡，有动机宣布一个低于实际值的平均准确率</li>
<li>平台报酬可能减少高准确率workers的数量</li>
<li>未来工作：<ol>
<li>多维workers异质性</li>
<li>考虑信息披露的代价（获取信息所产生的成本）</li>
</ol>
</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/134036707" target="_blank" rel="noopener">贝叶斯公式</a></li>
</ol>
<h2 id="我的分析"><a href="#我的分析" class="headerlink" title="我的分析"></a>我的分析</h2><h3 id="第三阶段workers均衡解定理1"><a href="#第三阶段workers均衡解定理1" class="headerlink" title="第三阶段workers均衡解定理1"></a>第三阶段workers均衡解定理1</h3><p>要用到的字母表达：</p>
<p>$P_{k^{high}-1}^{majority}$是指：当$k^{high}-1$个高准确率workers决定采取策略$(1,1)$且剩下的其他workers都决定采取策略$(0,rd)$时，$N-1$个workers的解决方案中的大多数是正确的概率（也就是多数一致方案是正确的概率）</p>
<p>$P_{k^{low}-1}^{majority}$是指：当$k^{low}-1$个高准确率workers决定采取策略$(1,1)$且剩下的其他workers决定采取策略$(0,rd)$时，$N-1$个workers的解决方案中的大多数是正确的概率（也就是多数一致方案是正确的概率）</p>
<p>$P_{k^{high}}^{majority}$是指：$k^{high}$个高准确率worker决定采取策略$(1,1)$，剩下的其他workers决定采取策略$(0,rd)$时，$N-1$个workers的解决方案中的大多数是正确的概率（也就是多数一致方案是正确的概率）</p>
<p>$P_{k^{low}}^{majority}$是指：$k^{low}$个高准确率worker决定采取策略$(1,1)$，剩下的其他workers决定采取策略$(0,rd)$时，$N-1$个workers的解决方案中的大多数是正确的概率（也就是多数一致方案是正确的概率）</p>
<p>$\mu_{high}^{post,str}|k_p^{anu}(\epsilon)$和$\mu_{low}^{post,str}|k_p^{anu}(\epsilon)$是高质量workers的数量的后验概率</p>
<p>我增加的字母表达：$P^{00}$表示高低质量都采取$(0,rd)$时多数一致方案是正确的概率，$P^{01}$表示高质量采取$(0,rd)$低质量采取$(1,-1)$…类似的，可以把workers策略组合的所有概率表达都写出来，上标左边的数字表示高质量workers的策略，右边的数字表示低质量workers的策略，数字012分别表示策略$(0,rd),(1,-1),(1,1)$。</p>
<p>显然，$P^{00}=0.5$，$P^{20}=\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}}^{majority}$</p>
<p>本文假设相同质量的workers会采取相同的策略，也就是说，高低质量的workers的策略组合一共有9种，我们列出收益矩阵：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>(0,rd)</th>
<th>(1,-1)</th>
<th>(1,1)</th>
</tr>
</thead>
<tbody>
<tr>
<td>(0,rd)</td>
<td>$(0.5R, 0.5R)$</td>
<td></td>
<td></td>
</tr>
<tr>
<td>(1,-1)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(1,1)</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h4 id="低质量workers选-0-rd"><a href="#低质量workers选-0-rd" class="headerlink" title="低质量workers选$(0,rd)$"></a>低质量workers选$(0,rd)$</h4><ol>
<li>高质量workers选$(0,rd)$，所有workers的答案是正确和错误的概率都是0.5，因此大家的收益都是$0.5R$，没有支出。</li>
<li>高质量workers选$(1,1)$，高质量workers正确的概率是$p_h$，低质量workers正确的概率是0.5，多数一致方案正确的概率是$\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}}^{majority}$，</li>
<li>高质量workers选$(1,-1)$，高质量workers正确的概率是$1-p_h$，低质量workers正确的概率是0.5，多数一致方案正确的概率是$P^{10}$。</li>
</ol>
<h4 id="低质量workers选-1-1"><a href="#低质量workers选-1-1" class="headerlink" title="低质量workers选$(1,-1)$"></a>低质量workers选$(1,-1)$</h4><ol>
<li>高质量workers选$(0,rd)$，高质量workers正确的概率是0.5，低质量workers正确的概率是$1-p_l$，多数一致方案正确的概率是$P^{01}$。</li>
<li>高质量workers选$(1,1)$，高质量workers正确的概率是$p_h$，低质量workers正确的概率是$1-p_l$，多数一致方案正确的概率是$P^{21}$。</li>
<li>高质量workers选$(1,-1)$，高质量workers正确的概率是$1-p_h$，低质量workers正确的概率是$1-p_l$，多数一致方案正确的概率是$P^{11}$。</li>
</ol>
<h4 id="低质量workders选-1-1"><a href="#低质量workders选-1-1" class="headerlink" title="低质量workders选$(1,1)$"></a>低质量workders选$(1,1)$</h4><ol>
<li>高质量workers选$(0,rd)$，高质量workers正确的概率是0.5，低质量workers正确的概率是$p_l$，多数一致方案正确的概率是$P^{02}$。</li>
<li>高质量workers选$(1,1)$，高质量workers正确的概率是$p_h$，低质量workers正确的概率是$p_l$，多数一致方案正确的概率是$P^{22}$。</li>
<li>高质量workers选$(1,-1)$，高质量workers正确的概率是$1-p_h$，低质量workers正确的概率是$p_l$，多数一致方案正确的概率是$P^{12}$。</li>
</ol>
<p>这里看起来是把每一个都列出来，然后比较大小找均衡解。</p>
<h4 id="Condition-11-的推导"><a href="#Condition-11-的推导" class="headerlink" title="$Condition(11)$的推导"></a>$Condition(11)$的推导</h4><p>在$p-SNE$的情况下，高准确率的worker采取策略$(1,1)$，低准确率的worker采取策略$(0,rd)$。</p>
<p>对于一个高质量worker，该workers努力时得到正确答案概率：$p_h$，得到错误答案概率：$1-p_h$。</p>
<p>其他workers中，高质量workers的数量$k$为$k^{high}-1$或者$k^{low}-1$，且对应的概率分别是两个后验概率$\mu_{high}^{post,str}|k_p^{anu}(\epsilon)$和$\mu_{low}^{post,str}|k_p^{anu}(\epsilon)$，而这两种情况下其他workers的多数一致方案是正确和错误的概率分别是$P_{k^{high}-1}^{majority}$和$P_{k^{low}-1}^{majority}$，即可得：</p>
<p>其他workers的多数一致方案是正确的概率：$\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}-1}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}-1}^{majority}$，</p>
<p>其他workers的多数一致方案是错误的概率：$\mu_{high}^{post,str}|k_p^{anu}(\epsilon)(1-P_{k^{high}-1}^{majority})+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)(1-P_{k^{low}-1}^{majority})$</p>
<p>一个努力且如实报告的高质量worker得到收益的概率为：</p>
<script type="math/tex; mode=display">
p_h(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}-1}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}-1}^{majority})+(1-p_h)(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)(1-P_{k^{high}-1}^{majority})+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)(1-P_{k^{low}-1}^{majority})) \tag{1}</script><p>对于一个低质量worker而言，该workers努力时得到正确答案概率：$p_l$，得到错误答案概率：$1-p_l$，其他workers中，高质量workers的数量$k$为$k^{high}$或者$k^{low}$，且对应的概率分别是两个后验概率$\mu_{high}^{post,str}|k_p^{anu}(\epsilon)$和$\mu_{low}^{post,str}|k_p^{anu}(\epsilon)$，而这两种情况下其他workers的多数一致方案是正确和错误的概率分别是$P_{k^{high}}^{majority}$和$P_{k^{low}}^{majority}$，即可得：</p>
<p>其他workers的多数一致方案是正确的概率：$\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}}^{majority}$，</p>
<p>其他workers的多数一致方案是错误的概率：$\mu_{high}^{post,str}|k_p^{anu}(\epsilon)(1-P_{k^{high}}^{majority})+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)(1-P_{k^{low}}^{majority})$</p>
<p>一个努力且如实报告的低质量worker得到收益的概率为：</p>
<script type="math/tex; mode=display">
p_l(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}}^{majority})+(1-p_l)(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)(1-P_{k^{high}}^{majority})+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)(1-P_{k^{low}}^{majority})) \tag{2}</script><p>公式(1)大于公式(2)所推导出的公式和论文中的$condition(11)$不一样，暂时没想到其他的思路。</p>
<p>这里推导出的是：</p>
<script type="math/tex; mode=display">
(1-p_h)(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)+\mu_{low}^{post,str}|k_p^{anu}(\epsilon))+(2p_h-1)(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}-1}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}-1}^{majority})\geq \\
(1-p_l)(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)+\mu_{low}^{post,str}|k_p^{anu}(\epsilon))+(2p_l-1)(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}}^{majority})</script><p>论文里的11是：</p>
<script type="math/tex; mode=display">
\frac{2p_h-1}{2p_l-1}(\mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}-1}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}-1}^{majority})\geq \mu_{high}^{post,str}|k_p^{anu}(\epsilon)P_{k^{high}}^{majority}+\mu_{low}^{post,str}|k_p^{anu}(\epsilon)P_{k^{low}}^{majority} \tag{11}</script><h3 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h3><ol>
<li>均衡解和阈值是怎么算出来的完全不懂</li>
<li>实验部分是怎么算最优平台披露策略$\epsilon^h,\epsilon^l$</li>
<li>图2(b)中增加的那段没有解释</li>
<li>$k^{high}=50$和$k^{high}=70$只有两个值是否能充分说明变化趋势（这个不重要）</li>
<li>社会财富的增加是否与平台数值过大有关（这个也不重要）</li>
<li>多数一致投票的时候，如果两边一样怎么处理（这个还不重要）</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://likun1208.github.io/2020/12/25/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95-Strategic%20Information%20Revelation%20in%20Crowdsourcing%20Systems%20Without%20Verification/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/crowdsourcing/" rel="tag">crowdsourcing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/game-theory/" rel="tag">game theory</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2021/01/06/ck3mod%E5%88%B6%E4%BD%9C%E7%AC%94%E8%AE%B0-8/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            ck3mod制作笔记-8
          
        </div>
      </a>
    
    
      <a href="/2020/12/24/ck3mod%E5%88%B6%E4%BD%9C%E7%AC%94%E8%AE%B0-7/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">ck3mod制作笔记-7</div>
      </a>
    
  </nav>

  
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2020-2024
        <i class="ri-heart-fill heart_icon"></i> Kun Li
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        由 <a href="https://hexo.io" target="_blank">Hexo</a> 强力驱动
        <span class="division">|</span>
        主题 - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/header.jpg" alt="左边"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/photos">照片</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/cv-ch">个人简历</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/cv-en">Resume</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->


<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>

<!-- Katex -->

<!-- busuanzi  -->

<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
<div id="waifu">
    <div id="waifu-message"></div>
    <div class="waifu-tool">
        <span class="icon-next"></span>
        <span class="icon-home"></span>
        <span class="icon-message"></span>
        <span class="icon-camera"></span>
        <span class="icon-volumeup"></span>
        <span class="icon-volumedown"></span>
        <span class="icon-about"></span>
        <span class="icon-cross"></span>
    </div>
    <canvas id="live2d2" style="top:150px"></canvas>
    <canvas id="live2d4" style="top:150px"></canvas>
</div>
<!--    src 中改为你存放的路径    -->
<script src="/dist/live2d_bundle.js"></script>
<script async type="module" src="/js/waifu-tips.js"></script>

</body>

</html>